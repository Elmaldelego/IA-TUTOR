ğŸš€ **Project Name: Open Tutor AI**
âœ¨ Project Description
This project is an artificial intelligence app that seeks to revolutionize educational feedback in basic education. Using the power of Google's Gemma 3n multimodal model, the model offers students a personalized tutor that works directly on their mobile devices, currently using Google AI Edge Gallery. ğŸ“±

Our solution aligns with and deepens the principles of expected learning outcomes for basic education, providing a tool that promotes autonomous learning and addresses the educational gap in low-resource areas. ğŸ«
If you like the app, feel free support me here:

<a href='https://ko-fi.com/emilianodorantes' target='_blank'><img height='42' style='border:0px;height:42px;' src='https://storage.ko-fi.com/cdn/kofi6.png?v=6' border='0' alt='Buy Me a Coffee at ko-fi.com' /></a>

ğŸ§ The Problem
In schools in marginalized and low-resource areas, teachers often lack the time and resources to offer personalized and timely feedback to each of their students. This lack of individualized support can hinder learning and understanding, which exacerbates educational inequality. ğŸ’”

ğŸ’¡ Our Solution
We have developed a mobile application with the following features:

Multimodal Feedback: Students can submit their work via text âœï¸ or images ğŸ“¸ (photos of their notebooks, drawings, diagrams) and the AI provides them with constructive feedback.

Offline Operation: The app is designed to work without an internet connection, making it ideal for areas with limited connectivity. ğŸ“¶

Learning Aligned with NEM and LTG: The AI model has been trained on the pedagogical principles of NEM and the content of the LTG, ensuring that the feedback is relevant and accurate. ğŸ“š

Personalized Tutor in Your Pocket: The AI not only corrects, but also guides the student to understand their mistakes and to improve, acting as an accessible personal tutor at all times. ğŸ¤–

âš™ï¸ How It Works
Our project is built on a robust architecture that combines the best of modern artificial intelligence:

Base Model: We use Gemma 3n, a multimodal AI model from Google, optimized to run on mobile devices.

Efficient Fine-tuning: Through the Unsloth framework, we have managed to fine-tune Gemma 3n quickly and with minimal memory usage. âš¡

Training Dataset:

Content: The model was trained with a data corpus that includes the official documents of the Nueva Escuela Mexicana and the complete content of the Libros de Texto Gratuitos.

Synthetic Data Generation: To overcome the scarcity of real assignments and ensure privacy, we have used Meta Llama's Synthetic Data Kit (SDK) to generate thousands of synthetic examples of student work and their ideal feedback. ğŸ¤–

User Flow:

The student uploads an image or writes their question.

The on-device model analyzes the input.

It generates a text response, which is then converted to speech using the phone's native Text-to-Speech (TTS) engine. ğŸ—£ï¸

The app can also analyze the chat history to identify knowledge gaps and generate a personalized study plan. ğŸ§ 

Usage instructions:

Download the fine-tuned model to the mobile device

Download the Google AI Edge Gallery APK

Load the fine-tuned model

Load the system prompts as the first instruction in the chat section

Ask the questions

ğŸ› ï¸ Technologies Used
AI Model: Gemma 3n (Google)

Optimization and Fine-tuning: Unsloth

Synthetic Data Generation: Synthetic Data Kit (Meta Llama)

On-Device Inference Frameworks: TensorFlow Lite / ONNX Runtime

Development Platforms: Android / iOS

UI/UX Prototype: Figma

ğŸ¥ Demo and Presentation
We invite you to watch the video of our demo to see the project in action. Don't miss it! ğŸ˜‰

[Link to the demo video on YouTube/Vimeo]

ğŸš€ Future and Scalability
This project is a proof of concept with enormous growth potential to address even greater educational challenges. Our future ideas include:

UI Development: An APK will be created based on Google AI Edge Gallery to provide a more user-friendly interface.

Integration into Educational Platforms: Expand the application beyond the student's device, integrating it into learning management systems (LMS) and platforms used by schools. ğŸŒ

Tool for the Teacher: Develop a control panel for teachers that allows them to visualize common knowledge gaps, analyze progress, and get suggestions for activities based on the NEM. ğŸ‘©â€ğŸ«

Translation to Mexican Sign Language (LSM): Leverage the multimodal capabilities of the AI to translate text feedback into an avatar that signs in LSM, making education more accessible for students with hearing disabilities. ğŸ¤Ÿ

Interdisciplinary Content: Expand the fine-tuning to cover all the formative fields of the NEM, promoting interdisciplinary thinking and the connection between different subjects. ğŸ§©

Community and Collaboration: Create a platform for teachers to share their own examples of feedback and materials, enriching the training corpus and adapting the AI to various pedagogical methodologies. ğŸ¤

Our ultimate goal is to offer a tool that serves as a true driver of educational equity, adapting to the needs of each student and empowering teachers nationwide. ğŸ’ª

ğŸ¤ Contributions
This project was developed by Emiliano Dorantes & Karen Espinosa
Especial agradecimiento por sus contribuciones a la comunidad: 
**unsloth:** https://github.com/unslothai/unsloth
**ChatterUI:** https://github.com/Vali-98/ChatterUI 

